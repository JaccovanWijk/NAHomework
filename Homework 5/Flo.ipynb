{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50472bda-279b-416b-9c5b-6fc3b1ff814c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 1 (6 points)\n",
    "\n",
    "A bacterial population $P$ grows according to the geometric progression\n",
    "\n",
    "$$P_t = rP_{t-1}$$\n",
    "\n",
    "Where r is the growth rate. The following population counts $P_1 ,\\ldots, P_8$ (in billions) are observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ff320c-517a-45da-99a8-ca87efc419a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array( [0.19, 0.36, 0.69, 1.3, 2.5, 4.7, 8.5, 14] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc3b80-e915-4854-a878-35d0ba645f80",
   "metadata": {},
   "source": [
    "# (a)\n",
    "Read chapter 6.6 on Nonlinear Least squares. Use the Gauss-Newton Method to fit the model function $f(t, x_1, x_2) = x_1\\!\\cdot x_2^t$ to the data. Find estimates for the initial population $P_0=x_1$ and the growth rate $r=x_2$. Implement the Gauss-Newton method yourself (you may use linear algebra functions from `scipy` and `numpy`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492fe88-c321-4b8c-9bd8-236f815b1369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b56e7014-dda8-4984-8fce-d0a5a16d046f",
   "metadata": {},
   "source": [
    "# (b)\n",
    "Let $f$ be a vector valued function $f = [ f_1, \\ldots, f_m ]^T$. In weighted least squares one aims to minimize the objective function\n",
    "$$\n",
    "  \\phi(x) = \\frac{1}{2} \\sum_{i=1}^m W_{ii} ( y_i - f_i(x)) ^2 , \\qquad\n",
    "  W_{ii} = \\frac{1}{\\sigma_i^2} , \n",
    "$$\n",
    "where $\\sigma_i$ is an estimate of the standard deviation in the data point $y_i$. This is equivalent to the standard least squares problem \n",
    "$$\n",
    "\\min_x \\frac{1}{2} \\| Y - F(x) \\|_2^2\n",
    "$$\n",
    "with $F_i(x) = \\frac{1}{\\sigma_i} f(x)$  , $Y_i = \\frac{1}{\\sigma_i} y_i$. Assume that for each data point $y_i$ in the list above, the estimate for the standard deviation is given by\n",
    "$$\n",
    "  \\sigma_i = 0.05 y_i .\n",
    "$$ \n",
    "Perform a weighted least squares fit to obtain estimates for $P_0$ and $r$. \n",
    "\n",
    "Plot the results of (a) and (b), showing the data points and the fitted curve. Compare the residuals\n",
    "(the values of $y_i - f_i(x)$) obtained in (a) and (b) and discuss the differences between the results of the weighted and the unweighted optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3a80a-d0f0-4b9f-8004-95b4e8ba7550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5d90471-4796-4f6d-b6ab-844805bf3d82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f0cbd35-09de-449a-80d5-c4da70b394bc",
   "metadata": {},
   "source": [
    "# Exercise 2 (3 points)\n",
    "A triangle has been measured. The measurements, a vector $x \\in \\mathbb{R}^6$, are as follows:\n",
    "$$\\begin{array}{c|c|c|c|c|c}\n",
    "x_1 = \\alpha \n",
    "& x_2 = \\beta\n",
    "& x_3 = \\gamma\n",
    "& x_4 = a\n",
    "& x_5 = b\n",
    "& x_6 = c \\\\ \\hline\n",
    "67.5^{\\large\\circ}\n",
    "& 52^{\\large\\circ}\n",
    "& 60^{\\large\\circ}\n",
    "& 172 \\text{m}\n",
    "& 146 \\text{m}\n",
    "& 165 \\text{m}\n",
    "\\end{array} .\n",
    "$$\n",
    "Here $\\alpha, \\beta, \\gamma$ are the angles opposite the sides with length $a$, $b$, $c$, respectively.\n",
    "The measurements $x$ have errors. We would like to correct them so that the new values $\\tilde{x} = x + h$ are consistent quantities of a triangle. The have to satisfy:\n",
    "$$ \\tag{*}\n",
    "\\begin{array}{ccc}\n",
    "\\text{Sum of angles:} \n",
    "& \\;\\;\\;\\;\\; & \n",
    "\\tilde{x}_1 + \\tilde{x}_2 + \\tilde{x}_3 = 180^{\\large\\circ}\n",
    "\\\\\n",
    "\\text{Sine theorem:}\n",
    "&&\n",
    "\\tilde{x}_4 \\sin(\\tilde{x}_2) - \\tilde{x}_5 \\sin(\\tilde{x}_1) = 0\n",
    "\\\\\n",
    "&&\n",
    "\\tilde{x}_5 \\sin(\\tilde{x}_3) - \\tilde{x}_6 \\sin(\\tilde{x}_2) = 0 .\n",
    "\\end{array}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c5137-9cf9-4f1e-9376-a2ca28ab2dd9",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Solve the constrained least squares problem $\\min_x \\| h \\|_2^2$ subject to the constraints given by (*).\n",
    "\n",
    "Use `scipy.optimize.minimize`.\n",
    "\n",
    "Hint: Don't forget to work in radians!\n",
    "\n",
    "Check that for the new values also e.g. the cosine theorem $c^2 = a^2 + b^2 - 2 ab \\cos(\\gamma)$ holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd180378-9e14-4e45-ac0d-4dedd620303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.04720163 0.99999772 1.0472033  1.04718773 0.99998822 0.99998666]\n",
      "3.094402641434005\n",
      "0.015159556252400508\n",
      "0.04944029273353567\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_deg = np.array([67.5,52,60,172,146,165])\n",
    "x_rad = np.array([1.178,0.907,1.047,172,146,165])\n",
    "x_guess = np.array([1,1,1,1,1,1])\n",
    "\n",
    "\n",
    "def con1(x):\n",
    "    return(x[0] + x[2] + x[3] - np.pi)\n",
    "\n",
    "\n",
    "def con2(x):\n",
    "    return  x[3] * np.sin(x[1]) - x[4] * np.sin(x[0])\n",
    "\n",
    "def con3(x):\n",
    "    return x[4] * np.sin(x[2]) - x[5] * np.sin(x[1])\n",
    "\n",
    "\n",
    "def lst(x,*args):\n",
    "    h = args[0] - x\n",
    "    norm = la.norm(h)\n",
    "    return 0.5 * norm **2\n",
    "\n",
    "cons = [ {\n",
    "    'type':'eq',\n",
    "    'fun': con1\n",
    "    },\n",
    "    {\n",
    "    'type':'ineq',\n",
    "    'fun': con2\n",
    "    }, \n",
    "    {\n",
    "    'type':'ineq',\n",
    "    'fun': con3\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "results = minimize(lst, x_rad, args=(x_guess,),constraints = cons).x\n",
    "\n",
    "\n",
    "\n",
    "print(results)\n",
    "\n",
    "# h_guess = results.x\n",
    "\n",
    "\n",
    "print(results[0]+results[1]+results[2])\n",
    "print(results[3]*np.sin(results[1])-results[4]*np.sin(results[0]))\n",
    "test_0 = (results[3]**2 + results[4]**2) - (2*results[3]*results[4]*np.cos(results[2])) - results[5]**2\n",
    "print(test_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f5e56-d57b-44f6-878f-d8d420d4d0a2",
   "metadata": {},
   "source": [
    "## (b)\n",
    "You will notice that the corrections will be made mainly to the angles and much less to the lengths of the sides of the triangle. This is because the measurements have not the same absolute errors. While the error in last digit of the sides is about 1, the errors in radians of the angles are about 0.01. Repeat your computation by taking in account with appropriate weighting the difference in measurement errors. Minimize not simply $\\| h \\|_2^2$ but\n",
    "$$\n",
    "  \\left\\| \\begin{bmatrix} 100 h_1 \\\\ 100 h_2 \\\\ 100 h_3 \\\\ h_4 \\\\ h_5 \\\\ h_6 \\end{bmatrix} \\right\\|_2^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc292e7-2304-4676-8d39-25f5a33246f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 38468.06589619741\n",
      "     jac: array([-466.77294922,  176.21240234,   -0.86962891, -170.16503906,\n",
      "       -144.38134766, -164.64501953])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 79\n",
      "     nit: 10\n",
      "    njev: 9\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1.13132592, 0.92462324, 0.17604452, 1.83422221, 1.61819775,\n",
      "       0.3549697 ])\n",
      "0.012413193267118539\n"
     ]
    }
   ],
   "source": [
    "def lst_w(x,*args):\n",
    "    h = args[0] - x\n",
    "    for i in range(2):\n",
    "        h[i] *= 100\n",
    "    norm = la.norm(h)\n",
    "    return 0.5 * norm **2\n",
    "    \n",
    "\n",
    "print(minimize(lst_w, x_guess, args=(x_rad,),constraints = cons))\n",
    "results = minimize(lst_w, x_guess, args=(x_rad,),constraints = cons).x\n",
    "\n",
    "test_w = (results[3]**2 + results[4]**2) - (2*results[3]*results[4]*np.cos(results[2])) - results[5]**2\n",
    "print(test_w)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
